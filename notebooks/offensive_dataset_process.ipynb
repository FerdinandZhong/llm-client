{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb2881c8-3bdc-4859-b049-98a962b2c269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0c5702-2d50-4d8f-b267-e92421cf7182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_a  \\\n",
       "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1  90194  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...       OFF   \n",
       "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_table(\"/root/autodl-tmp/datasets/offenseval/datasets/training-v1/offenseval-training-v1.tsv\")\n",
    "\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d752c5-efa8-4585-a5ca-15dde23bbdb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bi_split_dataframe(df, target_column, target_value):\n",
    "    grouped = df.groupby(df[target_column] == target_value)\n",
    "    \n",
    "    split_1 = grouped.get_group(True).reset_index().drop(\"index\", axis=1)\n",
    "    split_2 = grouped.get_group(False).reset_index().drop(\"index\", axis=1)\n",
    "    \n",
    "    return split_1, split_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82aa6189-a83a-46e8-8b71-40e063ce368b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "off_df, not_off_df = bi_split_dataframe(raw_df, \"subtask_a\", \"OFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54619cff-ef32-4765-92ef-4a1824deac67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97670</td>\n",
       "      <td>@USER Liberals are all Kookoo !!!</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77444</td>\n",
       "      <td>@USER @USER Oh noes! Tough shit.</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_a  \\\n",
       "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1  90194  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...       OFF   \n",
       "2  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "3  97670                  @USER Liberals are all Kookoo !!!       OFF   \n",
       "4  77444                   @USER @USER Oh noes! Tough shit.       OFF   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       UNT       NaN  \n",
       "3       TIN       OTH  \n",
       "4       UNT       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e871553-da73-45bf-906f-b6cce54f6f82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USER She should ask a few native Americans what their take on this is.\n"
     ]
    }
   ],
   "source": [
    "print(off_df.iloc[0][\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c18c52b-87df-485b-af0b-cc8ea78155d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT\n"
     ]
    }
   ],
   "source": [
    "print(not_off_df.iloc[0][\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6165fcc-aa87-4152-8ed0-7ee035b61f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90404726-fd04-4ca5-ab81-dcef9cdfd1e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USER Canada 0 12 ORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"@USER Canada\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0a9825-86be-4337-85b0-77497b4b0780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_labels = [\"GPE\", \"NORP\"]\n",
    "\n",
    "off_tweet_list = off_df[\"tweet\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa65165b-ce9b-4b84-bd76-19a4d7957129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 78.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORP Americans\n",
      "ORG @USER Liberals\n",
      "ORG @USER\n",
      "ORG @USER Canada\n",
      "GPE nâ€™t\n",
      "MONEY #LooneyLeft #Liberals\n",
      "MONEY #Qproofs #\n",
      "MONEY #DeepStateCorruption\n",
      "NORP PutUpOrShutUp\n",
      "ORG MAGA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "off_tweet_national_related_dict = {}\n",
    "\n",
    "for idx, tweet in enumerate(tqdm(off_tweet_list[:10])):\n",
    "    ents = nlp(tweet).ents\n",
    "    if len(ents) <= 0:\n",
    "        continue\n",
    "    else:\n",
    "        for ent in ents:\n",
    "            print(ent.label_, ent.text)\n",
    "            if ent.label_ in target_labels:\n",
    "                if idx not in off_tweet_national_related_dict:\n",
    "                    off_tweet_national_related_dict[idx] = {\n",
    "                        \"nationality_entities\": [ent.text],\n",
    "                        \"tweet\": tweet,\n",
    "                    }\n",
    "                else:\n",
    "                    off_tweet_national_related_dict[idx][\"nationality_entities\"].append(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdf54c81-74f5-4600-afff-a9ba854aef56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(off_tweet_national_related_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c0f3dcc-91e6-4d79-a0a5-9b576208b490",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  {'nationality_entities': ['Americans'],\n",
       "   'tweet': '@USER She should ask a few native Americans what their take on this is.'}),\n",
       " (6,\n",
       "  {'nationality_entities': ['nâ€™t'],\n",
       "   'tweet': '@USER Canada doesnâ€™t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo'}),\n",
       " (9,\n",
       "  {'nationality_entities': ['PutUpOrShutUp'],\n",
       "   'tweet': '@USER @USER @USER @USER LOL!!!   Throwing the BULLSHIT Flag on such nonsense!!  #PutUpOrShutUp   #Kavanaugh   #MAGA   #CallTheVoteAlready URL'}),\n",
       " (10,\n",
       "  {'nationality_entities': ['communist'],\n",
       "   'tweet': '@USER @USER Kind of like when conservatives wanna associate everyone to their left as communist antifa members?'}),\n",
       " (13,\n",
       "  {'nationality_entities': ['Democrat', 'nâ€™t bash'],\n",
       "   'tweet': '@USER @USER @USER She?  To whom are you referring to?  Hillary?  You know what is tiresome?  Bernie supporters bashing Hillary Clinton.  She is an actual Democrat who raises money for the Democratic Party and doesnâ€™t bash them.  She has a positive message.  So who is dividing the left?'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(off_tweet_national_related_dict.items(), 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb946f-e333-4041-ab50-25249e27d003",
   "metadata": {},
   "source": [
    "## Use LLM to Find Nationality NERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "13aa6cdf-7d5b-490c-86c3-17053825d67a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 23:53:26,643 - \u001b[32mINFO\u001b[0m - pipeline.py:20 - pipeline.__init__ - 5563 - parameters for every request: {'do_sample': False, 'max_new_tokens': 64, 'repetition_penalty': None, 'return_full_text': False, 'seed': None, 'temperature': None, 'top_k': None, 'top_p': None, 'truncate': None, 'typical_p': None, 'best_of': None, 'watermark': False, 'decoder_input_details': False, 'stop_sequences': ['</s>', '[/INST]', '[/SYS>>', 'Question']}\n"
     ]
    }
   ],
   "source": [
    "from llm_client.pipeline import Pipeline\n",
    "from typing import List\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "config_yaml = \"/root/llm_client/config_yamls/llama2-hf.yaml\"\n",
    "\n",
    "pipeline = Pipeline(config_yaml, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4db275ee-e0d4-43b1-924e-4b8c764b81d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example=(\n",
    "    \"\\n[INST] Detect the nationality-related entity in the following quoted text: \"\n",
    "    \"\\\"My name is Wolfgang and I come from Germany\"\"[/INST]\"\n",
    "    \"\\nAnswer: The entity is \\\"Germeny\\\"\"\n",
    "    \"\\n[INST] Detect the nationality-related entity in the following quoted text: \"\n",
    "    \"\\\"My name is Wolfgang and I'm German\"\"[/INST]\"\n",
    "    \"\\nAnswer: The entity is \\\"German\\\"\"\n",
    "    \"\\n[INST] Detect the nationality-related entity in the following quoted text: \"\n",
    "    \"\\\"Amazon is investigating employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace.\"\"[/INST]\"\n",
    "    \"\\nAnswer: The entity is \\\"NONE\\\"\"\n",
    ")\n",
    "\n",
    "prompt_list = []\n",
    "for tweet in off_tweet_list:\n",
    "    prompt_list.append(\n",
    "        (\n",
    "            f\"{example}\\n[INST] Detect the nationality-related entity in the following quoted text: \\\"{tweet}\\\"[/INST]\"\n",
    "            # f\"return NONE if you can't find any: \\\"{tweet}\\\"[/INST]\"\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "91d1d94d-7a0d-47fe-902b-5e0a5681d842",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n[INST] Detect the nationality-related entity in the following quoted text: \"My name is Wolfgang and I come from Germany[/INST]\\nAnswer: The entity is \"Germeny\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"My name is Wolfgang and I\\'m German[/INST]\\nAnswer: The entity is \"German\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"Amazon is investigating employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace.[/INST]\\nAnswer: The entity is \"NONE\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"@USER She should ask a few native Americans what their take on this is.\"[/INST]',\n",
       " '\\n[INST] Detect the nationality-related entity in the following quoted text: \"My name is Wolfgang and I come from Germany[/INST]\\nAnswer: The entity is \"Germeny\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"My name is Wolfgang and I\\'m German[/INST]\\nAnswer: The entity is \"German\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"Amazon is investigating employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace.[/INST]\\nAnswer: The entity is \"NONE\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"@USER @USER Go home youâ€™re drunk!!! @USER #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL\"[/INST]',\n",
       " '\\n[INST] Detect the nationality-related entity in the following quoted text: \"My name is Wolfgang and I come from Germany[/INST]\\nAnswer: The entity is \"Germeny\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"My name is Wolfgang and I\\'m German[/INST]\\nAnswer: The entity is \"German\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"Amazon is investigating employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace.[/INST]\\nAnswer: The entity is \"NONE\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"@USER Someone should\\'veTaken\" this piece of shit to a volcano. ðŸ˜‚\"\"[/INST]',\n",
       " '\\n[INST] Detect the nationality-related entity in the following quoted text: \"My name is Wolfgang and I come from Germany[/INST]\\nAnswer: The entity is \"Germeny\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"My name is Wolfgang and I\\'m German[/INST]\\nAnswer: The entity is \"German\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"Amazon is investigating employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace.[/INST]\\nAnswer: The entity is \"NONE\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"@USER Liberals are all Kookoo !!!\"[/INST]',\n",
       " '\\n[INST] Detect the nationality-related entity in the following quoted text: \"My name is Wolfgang and I come from Germany[/INST]\\nAnswer: The entity is \"Germeny\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"My name is Wolfgang and I\\'m German[/INST]\\nAnswer: The entity is \"German\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"Amazon is investigating employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace.[/INST]\\nAnswer: The entity is \"NONE\"\\n[INST] Detect the nationality-related entity in the following quoted text: \"@USER @USER Oh noes! Tough shit.\"[/INST]']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "60cfe02d-dd5f-4234-b69d-76e471eb34d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def main(input_list: List, pipeline: Pipeline):\n",
    "    tasks = [pipeline.model_predict(input) for input in input_list]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bd6e22b0-10d9-4cad-9468-3f0ccf52f5c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entity is \"Native Americans\"\n",
      "===========\n",
      "The entity is \"NONE\"\n",
      "===========\n",
      "The entity is \"NONE\"\n",
      "===========\n",
      "The entity is \"NONE\"\n",
      "===========\n",
      "The entity is \"NONE\"\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "sample_list = prompt_list[:5]\n",
    "\n",
    "result_list = await main(sample_list, pipeline)\n",
    "for result in result_list:\n",
    "    print(result.split(\"\\n[INST]\")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f24640d-c815-4652-b249-564c7a625447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4400/4400 [12:54<00:00,  5.68it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result_list = []\n",
    "chunk_size = 50\n",
    "\n",
    "question_list = prompt_list.copy()\n",
    "pbar = tqdm(total = len(question_list))\n",
    "while len(question_list) > chunk_size:\n",
    "    current_chunk = question_list[:chunk_size]\n",
    "    question_list = question_list[chunk_size:]\n",
    "    \n",
    "    result_list = await main(current_chunk, pipeline)\n",
    "    train_result_list.extend([result_text.split(\"\\n[INST]\")[0] for result_text in result_list])\n",
    "    \n",
    "    pbar.update(chunk_size)\n",
    "    time.sleep(2)\n",
    "\n",
    "result_list = await main(question_list, pipeline)\n",
    "train_result_list.extend([result_text.split(\"\\n[INST]\")[0] for result_text in result_list])\n",
    "pbar.update(len(question_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3fd28fd7-2883-46a3-8ece-e27c3fa593cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"temp_off_nationality.txt\", \"w\") as output_file:\n",
    "    for result_text in train_result_list:\n",
    "        output_file.write(f\"{result_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0c4c2-2fef-43e8-a4da-81133136ffdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-tgi-env",
   "language": "python",
   "name": "llm-tgi-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
